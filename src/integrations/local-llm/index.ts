export const localLLM = {
  models: {
    ollama: {
      models: ['llama2', 'mistral', 'codellama'],
    },
    lmstudio: {
      models: ['gpt-3.5-turbo', 'gpt-4'],
    },
    gpt4all: {
      models: ['gpt4all-j', 'gpt4all-l13b-snoozy'],
    },
    gemini: {
      models: ['gemini-pro'],
    },
  },
};
